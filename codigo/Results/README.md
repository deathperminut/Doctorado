# Results - An√°lisis de Interpretabilidad

## üìã Descripci√≥n

Esta carpeta contiene notebooks dedicados al an√°lisis de interpretabilidad de los modelos entrenados. Se utilizan t√©cnicas de visualizaci√≥n (UMAP, Grad-CAM) y experimentos de ablaci√≥n para entender **qu√©** aprende la red y **c√≥mo** toma decisiones.

## üóÇÔ∏è Estructura

```
Results/
‚îú‚îÄ‚îÄ DatabaseJex2T/
‚îÇ   ‚îî‚îÄ‚îÄ Results.ipynb           # An√°lisis completo para Jex2 y Temperatura
‚îÇ
‚îî‚îÄ‚îÄ DatabaseKDMT/
    ‚îî‚îÄ‚îÄ Results.ipynb           # An√°lisis completo para KDM y Temperatura
```

## üéØ Objetivos del An√°lisis

1. **üìä Evaluaci√≥n cuantitativa**
   - R¬≤, MAPE, SMAPE en validation set
   - Gr√°ficos de predicci√≥n vs real

2. **üîç Interpretabilidad de features**
   - UMAP de activaciones por capa
   - Identificaci√≥n de representaciones aprendidas

3. **üé® Grad-CAM (Class Activation Maps)**
   - Heatmaps de atenci√≥n espacial
   - An√°lisis por rangos de par√°metros
   - Contribuci√≥n por capa convolucional

4. **üß™ Experimentos de ablaci√≥n**
   - Enmascaramiento de regiones
   - Impacto en performance

## üîÑ Flujo de An√°lisis

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             1. CARGA DE MODELO Y DATOS                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Modelo entrenado (.h5)                         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Validation dataset                             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Scaler (para desnormalizar predicciones)      ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              2. EVALUACI√ìN CUANTITATIVA                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Predicci√≥n en validation set                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ C√°lculo de m√©tricas (R¬≤, MAPE, SMAPE)         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Scatter plot: Real vs Predicted               ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Residual analysis                             ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              3. AN√ÅLISIS UMAP POR CAPA                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ Capas analizadas:                                ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ pool2_conv (capa temprana)                    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ conv3_block4_1_conv (media-temprana)         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ conv4_block7_2_conv (media-tard√≠a)           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ conv5_block16_concat (capa profunda)         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Proceso:                                         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  1. Extraer activaciones intermedias             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  2. Flatten features                             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  3. UMAP reduction (2D)                          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  4. Scatter plot coloreado por target           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Insight: Ver c√≥mo la red separa muestras        ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           4. CLUSTERING Y SELECCI√ìN DE MUESTRAS            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Seleccionar N im√°genes representativas         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ K-Means en espacio UMAP (4 clusters)          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Seleccionar 4 muestras por cluster            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Total: 16 im√°genes para an√°lisis profundo     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Criterio: Im√°genes m√°s cercanas a centroides    ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            5. GRAD-CAM: HEATMAPS DE ATENCI√ìN              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ A. Grad-CAM basado en Error Absoluto:           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ    loss = 1 - |y_real - y_pred|                 ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Identifica regiones que reducen error      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ B. Grad-CAM basado en MAPE:                     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ    loss = |y_real - y_pred| / |y_real|          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Penaliza m√°s errores relativos grandes     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Capas analizadas (10):                          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv2_block6_1_conv                            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv3_block5_1_conv                            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv3_block10_2_conv                           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv4_block4_2_conv                            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv4_block7_2_conv                            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv4_block11_1_conv                           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv4_block17_2_conv                           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv5_block2_1_conv                            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv5_block8_1_conv                            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  conv5_block16_1_conv                           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Output: Grilla 16√ó11 (im√°genes √ó capas)        ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        6. AN√ÅLISIS POR RANGOS DE PAR√ÅMETROS               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Dividir dataset en 5 rangos del par√°metro     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ   Ejemplo Jex2: [0.0-0.2, 0.2-0.4, ..., 0.8-1.0]‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Seleccionar 10 muestras representativas        ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ   por rango (cercanas al centro del rango)      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Visualizar: Grilla 10√ó5 (muestras √ó rangos)   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Generar Grad-CAM para 5 primeras muestras     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ   de cada rango                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Calcular contribuci√≥n promedio por capa       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ   en cada rango                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       7. GR√ÅFICO DE CONTRIBUCI√ìN POR CAPA/RANGO           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Bar plot: 5 rangos √ó 10 capas                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Eje X: Rangos del par√°metro                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Eje Y: Contribuci√≥n promedio Grad-CAM         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Barras: Una por capa (coloreadas)             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Insight: ¬øQu√© capas son m√°s importantes         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ          en cada rango del par√°metro?           ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         8. EXPERIMENTO DE ABLACI√ìN (MASKING)              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ Proceso:                                         ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  1. Generar Grad-CAM basado en MAPE             ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  2. Crear m√°scara binaria:                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ     mask = 0 donde heatmap > threshold          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ     mask = 1 donde heatmap ‚â§ threshold          ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  3. Aplicar m√°scara: img_masked = img * mask    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  4. Predecir en dataset enmascarado              ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  5. Comparar R¬≤ original vs R¬≤ enmascarado      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Hip√≥tesis:                                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Si R¬≤ baja mucho ‚Üí regiones eran importantes ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Si R¬≤ se mantiene ‚Üí regiones no cr√≠ticas     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Par√°metros experimentales:                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ threshold_factor: 0.7-0.8                    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ layer_to_mask: conv5_block2_1_conv           ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ subset_size: 100% del validation set         ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìä T√©cnicas de Interpretabilidad

### 1. UMAP (Uniform Manifold Approximation and Projection)

**Objetivo:** Visualizar representaciones aprendidas en espacios de alta dimensi√≥n

**Implementaci√≥n:**
```python
import umap
from tensorflow.keras.models import Model

# Extraer activaciones de capas espec√≠ficas
layer_names = ['pool2_conv', 'conv3_block4_1_conv',
               'conv4_block7_2_conv', 'conv5_block16_concat']

intermediate_models = [Model(inputs=model.input,
                             outputs=model.get_layer(name).output)
                      for name in layer_names]

# Procesar validation set
activations = {name: [] for name in layer_names}
for batch_x, batch_y in val_dataset:
    for name, inter_model in zip(layer_names, intermediate_models):
        act = inter_model.predict(batch_x)
        activations[name].append(act)

# Concatenar y aplanar
for name in layer_names:
    activations[name] = np.concatenate(activations[name], axis=0)
    activations[name] = activations[name].reshape(activations[name].shape[0], -1)

# UMAP reduction
reducer = umap.UMAP(n_components=2, n_neighbors=5, min_dist=0.5,
                    metric='cosine', n_epochs=200, low_memory=True)

for name in layer_names:
    embedding = reducer.fit_transform(activations[name])
    plt.scatter(embedding[:, 0], embedding[:, 1], c=y_real, cmap='jet')
    plt.colorbar()
    plt.title(f"UMAP - {name}")
    plt.show()
```

**Interpretaci√≥n:**
- Capas tempranas (pool2): Features gen√©ricos, poca separaci√≥n por par√°metro
- Capas medias (conv3-conv4): Comienza separaci√≥n progresiva
- Capas profundas (conv5): Clara separaci√≥n por valor del par√°metro

### 2. Grad-CAM (Gradient-weighted Class Activation Mapping)

**Objetivo:** Identificar qu√© regiones espaciales son importantes para la predicci√≥n

**Implementaci√≥n (basada en error):**
```python
def compute_gradcam_error(img_array, model, layer_name, y_real):
    # Crear modelo que retorna activaciones + predicci√≥n
    grad_model = tf.keras.models.Model(
        inputs=model.input,
        outputs=[model.get_layer(layer_name).output, model.output]
    )

    y_real_tensor = tf.constant([[y_real]], dtype=tf.float32)

    with tf.GradientTape() as tape:
        conv_output, predictions = grad_model(img_array, training=False)
        # Loss: queremos MAXIMIZAR cercan√≠a a y_real
        loss = 1.0 - tf.abs(y_real_tensor - predictions)

    # Gradiente de loss respecto a activaciones
    grads = tape.gradient(loss, conv_output)

    # Pooled gradients (importancia por canal)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Ponderar activaciones por importancia
    conv_output = conv_output.numpy()[0]
    pooled_grads = pooled_grads.numpy()

    for i in range(pooled_grads.shape[-1]):
        conv_output[:, :, i] *= pooled_grads[i]

    # Heatmap = promedio sobre canales
    heatmap = np.mean(conv_output, axis=-1)
    heatmap = np.maximum(heatmap, 0)  # ReLU
    heatmap /= np.max(heatmap) + 1e-8  # Normalizar

    return heatmap
```

**Implementaci√≥n (basada en MAPE):**
```python
def compute_gradcam_mape(img_array, model, layer_name, y_real, epsilon=1e-6):
    grad_model = tf.keras.models.Model(
        inputs=model.input,
        outputs=[model.get_layer(layer_name).output, model.output]
    )

    y_real_tensor = tf.cast(tf.constant([[y_real]]), tf.float32)

    with tf.GradientTape() as tape:
        conv_output, predictions = grad_model(img_array, training=False)
        # Loss: MAPE
        mape = tf.abs((y_real_tensor - predictions) / (tf.abs(y_real_tensor) + epsilon))
        loss = tf.reduce_mean(mape)

    grads = tape.gradient(loss, conv_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    conv_output = conv_output.numpy()[0]
    pooled_grads = pooled_grads.numpy()

    for i in range(pooled_grads.shape[-1]):
        conv_output[:, :, i] *= pooled_grads[i]

    heatmap = np.mean(conv_output, axis=-1)
    heatmap = np.maximum(heatmap, 0)
    heatmap /= np.max(heatmap) + 1e-6

    return heatmap
```

**Interpretaci√≥n:**
- **Heatmap rojo (alta activaci√≥n):** Regiones cr√≠ticas para predicci√≥n
- **Heatmap azul (baja activaci√≥n):** Regiones menos relevantes
- **Comparaci√≥n entre capas:** Capas profundas (conv5) m√°s espec√≠ficas, tempranas (conv2) m√°s globales

### 3. Clustering y Selecci√≥n de Muestras

**Objetivo:** Identificar im√°genes representativas de diferentes regiones del espacio latente

**Implementaci√≥n:**
```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# UMAP en im√°genes del validation set
images_flattened = images.reshape(num_samples, -1)
scaler = StandardScaler()
images_scaled = scaler.fit_transform(images_flattened)

reducer = umap.UMAP(n_components=2, n_neighbors=5, min_dist=0.5)
images_umap = reducer.fit_transform(images_scaled)

# K-Means clustering
kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
labels = kmeans.fit_predict(images_umap)
centroids = kmeans.cluster_centers_

# Seleccionar 4 im√°genes m√°s cercanas al centroide de cada cluster
selected_images = []
for i in range(4):
    cluster_indices = np.where(labels == i)[0]
    cluster_points = images_umap[cluster_indices]
    distances = np.linalg.norm(cluster_points - centroids[i], axis=1)
    closest_indices = cluster_indices[np.argsort(distances)[:4]]
    selected_images.extend([images[idx] for idx in closest_indices])
```

**Interpretaci√≥n:** Captura diversidad de patrones magn√©ticos presentes en el dataset

### 4. An√°lisis por Rangos

**Objetivo:** Entender c√≥mo var√≠a la atenci√≥n del modelo seg√∫n el valor del par√°metro

**Implementaci√≥n:**
```python
# Dividir par√°metro en 5 rangos equidistantes
num_bins = 5
y_min, y_max = y_real.min(), y_real.max()
bins = np.linspace(y_min, y_max, num_bins + 1)

# Asignar muestras a rangos
indices_por_rango = {i: [] for i in range(num_bins)}
for idx, y in enumerate(y_real):
    rango = np.digitize(y, bins) - 1
    rango = min(rango, num_bins - 1)
    indices_por_rango[rango].append(idx)

# Seleccionar im√°genes representativas por rango
centro_rango = (bins[:-1] + bins[1:]) / 2
imagenes_por_rango = {}
for rango, indices in indices_por_rango.items():
    # Ordenar por cercan√≠a al centro
    indices_ordenados = sorted(indices,
                               key=lambda i: abs(y_real[i] - centro_rango[rango]))
    imagenes_por_rango[rango] = [images[i] for i in indices_ordenados[:10]]
```

**Interpretaci√≥n:**
- Rangos bajos (0.0-0.2): ¬øQu√© patrones caracterizan valores bajos del par√°metro?
- Rangos altos (0.8-1.0): ¬øQu√© patrones caracterizan valores altos?
- Transiciones (0.4-0.6): ¬øRegiones ambiguas o transicionales?

### 5. Contribuci√≥n por Capa/Rango

**Objetivo:** Cuantificar la importancia de cada capa en diferentes rangos del par√°metro

**Implementaci√≥n:**
```python
# Diccionario para acumular contribuci√≥n
contribucion_por_rango = {rango: {layer: 0 for layer in layer_names}
                          for rango in rangos}

# Para cada rango
for rango, imagenes in imagenes_por_rango.items():
    num_images = len(imagenes)

    for i, img in enumerate(imagenes[:5]):  # Primeras 5 muestras
        img_array = np.expand_dims(img, axis=0)
        y_real_value = valores_por_rango[rango][i]

        for layer in layer_names:
            heatmap = compute_gradcam_error(img_array, model, layer, y_real_value)
            heatmap = np.maximum(heatmap, 0)
            if np.max(heatmap) > 0:
                heatmap /= np.max(heatmap)
            contribucion_por_rango[rango][layer] += np.mean(heatmap)

    # Normalizar por n√∫mero de im√°genes
    for layer in layer_names:
        contribucion_por_rango[rango][layer] /= num_images

# Visualizar
fig, ax = plt.subplots(figsize=(20, 10))
x = np.arange(len(rangos))
bar_width = 0.05

for i, layer in enumerate(layer_names):
    contribuciones = [contribucion_por_rango[r][layer] for r in rangos]
    ax.bar(x + i * bar_width, contribuciones, width=bar_width, label=layer)

ax.set_xlabel("Rangos")
ax.set_ylabel("Contribuci√≥n Promedio Grad-CAM")
ax.set_xticks(x + bar_width * 1.5)
ax.set_xticklabels(['0.0-0.2', '0.2-0.4', '0.4-0.6', '0.6-0.8', '0.8-1.0'])
ax.legend()
plt.show()
```

**Interpretaci√≥n:**
- Capas con alta contribuci√≥n ‚Üí importantes para discriminar ese rango
- Variaci√≥n entre rangos ‚Üí diferentes caracter√≠sticas espaciales relevantes

### 6. Experimento de Ablaci√≥n (Masking)

**Objetivo:** Validar que las regiones identificadas por Grad-CAM son realmente importantes

**Implementaci√≥n:**
```python
def create_mask(heatmap, threshold_factor=0.8):
    """M√°scara: 0 donde heatmap alto, 1 donde bajo"""
    threshold = np.max(heatmap) * threshold_factor
    mask = np.where(heatmap >= threshold, 0, 1).astype(np.float32)
    return mask

def generate_masked_dataset(model, val_dataset, layer_to_mask, threshold_factor):
    masked_images = []
    real_values = []

    for X_batch, y_batch in val_dataset:
        for i in range(len(X_batch)):
            img = X_batch.numpy()[i]
            y_real = y_batch.numpy()[i]
            img_array = np.expand_dims(img, axis=0)

            # Grad-CAM
            heatmap = compute_gradcam_mape(img_array, model, layer_to_mask,
                                          tf.constant([[y_real]]))
            resized_heatmap = tf.image.resize(np.expand_dims(heatmap, -1),
                                             img.shape[:2]).numpy()

            # Crear m√°scara y aplicar
            mask = create_mask(resized_heatmap, threshold_factor)
            masked_image = img * mask

            masked_images.append(masked_image)
            real_values.append(y_real)

    return tf.data.Dataset.from_tensor_slices((np.array(masked_images),
                                               np.array(real_values))).batch(32)

# Predecir en dataset enmascarado
masked_dataset = generate_masked_dataset(model, val_dataset,
                                        'conv5_block2_1_conv', 0.8)

y_pred_masked = model.predict(masked_dataset)
r2_masked = r2_score(y_real_masked, y_pred_masked)

print(f"R¬≤ original: {r2_original:.4f}")
print(f"R¬≤ enmascarado: {r2_masked:.4f}")
print(f"Degradaci√≥n: {(r2_original - r2_masked):.4f}")
```

**Interpretaci√≥n:**
- Degradaci√≥n grande (Œî R¬≤ > 0.2): Regiones eran cr√≠ticas ‚úÖ Grad-CAM correcto
- Degradaci√≥n peque√±a (Œî R¬≤ < 0.05): Regiones no tan importantes ‚ùå Revisar Grad-CAM

## üìä Resultados Principales (DatabaseJex2T)

### M√©tricas Finales

| Target | R¬≤ Score | MAPE | SMAPE | Interpretaci√≥n |
|--------|----------|------|-------|----------------|
| **Jex2** | **0.9753** | **18.64%** | **15.49%** | ‚úÖ Excelente predicci√≥n |
| **Temperatura** | -1.2353 | 287.11% | 67.29% | ‚ùå Predicci√≥n pobre |

### Insights de UMAP

- **Jex2:** Clara separaci√≥n en espacio latente de conv5
  - Valores bajos (azul) agrupados
  - Valores altos (rojo) agrupados
  - Transici√≥n gradual y continua

- **Temperatura:** Superposici√≥n en espacio latente
  - M√∫ltiples temperaturas generan configuraciones similares
  - Sugiere que informaci√≥n temporal es necesaria

### Insights de Grad-CAM

**Para Jex2:**
- **Capas tempranas (conv2):** Atenci√≥n global, poco espec√≠fica
- **Capas medias (conv3-conv4):** Comienza focalizaci√≥n en interfaces
- **Capas profundas (conv5):** Alta atenci√≥n en:
  - **Interfaces entre dominios** (bordes de regiones)
  - **Defectos topol√≥gicos** (skyrmions, v√≥rtices)
  - **Transiciones abruptas** de magnetizaci√≥n

**Por rangos:**
- **Jex2 bajo (0.0-0.2):** Modelo se enfoca en regiones de alta homogeneidad
- **Jex2 alto (0.8-1.0):** Modelo se enfoca en estructuras coherentes extensas

### Experimentos de Ablaci√≥n

```
Layer: conv5_block2_1_conv
Threshold: 0.8
Subset: 100% validation

R¬≤ original:    0.9753
R¬≤ enmascarado: 0.7821
Degradaci√≥n:    0.1932  ‚Üê Confirma importancia de regiones identificadas
```

**Conclusi√≥n:** Grad-CAM identifica correctamente regiones cr√≠ticas

## üìà Visualizaciones Generadas

Cada notebook genera los siguientes outputs:

1. **scatter_real_vs_pred.svg** - Gr√°fico de dispersi√≥n predicciones
2. **UMAP_visualization_jex2.svg** - UMAP por capa para Jex2
3. **UMAP_visualization_T.svg** - UMAP por capa para Temperatura
4. **Clustered_Images_UMAP_4Clusters_4Each.svg** - Im√°genes representativas
5. **gradcam_results.svg** - Heatmaps para muestras seleccionadas
6. **gradcam_<rango>.svg** - Heatmaps por cada rango (5 archivos)
7. **mean_contribution_gradcam.svg** - Contribuci√≥n por capa/rango (Error)
8. **mean_contribution_gradcam_MAPE.svg** - Contribuci√≥n por capa/rango (MAPE)

## üöÄ C√≥mo Ejecutar el An√°lisis

### Paso 1: Cargar Modelo

```python
from tensorflow.keras.models import load_model

model_jex2 = load_model('modelo_densenet_regresionY_2.h5',
                        custom_objects={'mse': tf.keras.losses.MeanSquaredError()})
```

### Paso 2: Preparar Validation Dataset

```python
# Cargar dataset
data = np.load('spinesv0.npz')
X = data['X'][:, :42, :, :]
y_jex2 = data['y'][:, 0].reshape(-1, 1)

# Preprocesar
processed_images = preprocess_images(X)

# Split
X_train, X_val, y_train, y_val = train_test_split(processed_images, y_jex2,
                                                   test_size=0.1, random_state=42)

# Dataset
val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(32)
```

### Paso 3: Ejecutar Secciones del Notebook

- **Secci√≥n 1-2:** Evaluaci√≥n cuantitativa
- **Secci√≥n 3:** UMAP por capa
- **Secci√≥n 4:** Clustering
- **Secci√≥n 5-6:** Grad-CAM
- **Secci√≥n 7:** An√°lisis por rangos
- **Secci√≥n 8:** Experimentos de ablaci√≥n

### Paso 4: Guardar Visualizaciones

```python
plt.savefig("figura.svg", format="svg", dpi=300, bbox_inches="tight")
```

## üêõ Troubleshooting

**Problema:** UMAP muy lento
- **Soluci√≥n:** Usar `low_memory=True`, reducir `n_epochs`, o samplear subset

**Problema:** Grad-CAM todo negro/blanco
- **Soluci√≥n:** Verificar normalizaci√≥n de heatmap, ajustar colormap, revisar gradientes

**Problema:** Memory Error en ablaci√≥n
- **Soluci√≥n:** Procesar en batches m√°s peque√±os, reducir subset_size

## üìö Referencias

- **Grad-CAM:** Selvaraju et al. (2017) - "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"
- **UMAP:** McInnes et al. (2018) - "UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction"

## üîó Conexi√≥n con Papers

Los an√°lisis de este notebook proporcionan:
- **Figuras para publicaci√≥n:** UMAP, Grad-CAM, contribuci√≥n por capa
- **Validaci√≥n cient√≠fica:** Ablation studies demuestran que el modelo aprende f√≠sica relevante
- **Insights f√≠sicos:** Identificaci√≥n de caracter√≠sticas magn√©ticas relevantes (interfaces, defectos)

---

**Nota:** Este an√°lisis es cr√≠tico para papers cient√≠ficos, ya que demuestra que el modelo no solo "funciona" sino que aprende representaciones f√≠sicamente interpretables.
