# PredicciÃ³n de ParÃ¡metros Hamiltonianos en Dominios MagnÃ©ticos mediante Deep Learning

## ğŸ“‹ DescripciÃ³n General

Este proyecto investiga el uso de redes neuronales convolucionales (CNNs) profundas para predecir parÃ¡metros fÃ­sicos de sistemas magnÃ©ticos (hamiltonianos) a partir de imÃ¡genes de configuraciones de spin. Se utilizan mÃºltiples arquitecturas de deep learning (DenseNet, ResNet, EfficientNet, InceptionNet) para establecer relaciones entre patrones espaciales de magnetizaciÃ³n y sus parÃ¡metros fÃ­sicos subyacentes.

## ğŸ¯ Objetivo

Desarrollar modelos de aprendizaje profundo capaces de:
1. Predecir parÃ¡metros del hamiltoniano (Jex2, KDM, Temperatura) a partir de imÃ¡genes de estados magnÃ©ticos
2. Identificar quÃ© caracterÃ­sticas espaciales de los dominios magnÃ©ticos son mÃ¡s relevantes para cada parÃ¡metro
3. Interpretar las decisiones del modelo mediante tÃ©cnicas de visualizaciÃ³n (UMAP, Grad-CAM)

## ğŸ“Š Bases de Datos

El proyecto trabaja con dos bases de datos de simulaciones magnÃ©ticas:

### 1. **DatabaseJex2T**
- **ParÃ¡metros variables:** Jex2 (interacciÃ³n de intercambio) y Temperatura (T)
- **ImÃ¡genes:** Configuraciones espaciales de spin (39Ã—39 pÃ­xeles)
- **Total muestras:** ~54,044 imÃ¡genes
- **Objetivo:** Predecir Jex2 y T a partir de patrones de magnetizaciÃ³n

### 2. **DatabaseKDMT**
- **ParÃ¡metros variables:** KDM (anisotropÃ­a Dzyaloshinskii-Moriya) y Temperatura (T)
- **ImÃ¡genes:** Configuraciones espaciales de spin (39Ã—39 pÃ­xeles)
- **Total muestras:** Variable segÃºn construcciÃ³n
- **Objetivo:** Predecir KDM y T a partir de patrones de magnetizaciÃ³n

## ğŸ”„ Flujo de Trabajo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. PREPROCESSING                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Archivos .dat  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Construction.ipynbâ”‚           â”‚
â”‚  â”‚ (Simulaciones) â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚                      â”‚
â”‚                                      â–¼                       â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                        â”‚  ImÃ¡genes de Spin       â”‚          â”‚
â”‚                        â”‚  (39Ã—39Ã—1 â†’ 224Ã—224Ã—3)  â”‚          â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                 â”‚                            â”‚
â”‚                                 â–¼                            â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                        â”‚ DescriptionRescale   â”‚             â”‚
â”‚                        â”‚ â€¢ NormalizaciÃ³n      â”‚             â”‚
â”‚                        â”‚ â€¢ VisualizaciÃ³n UMAP â”‚             â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                   â”‚                          â”‚
â”‚                                   â–¼                          â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                        â”‚ Dataset .npz         â”‚             â”‚
â”‚                        â”‚ (Kaggle Storage)     â”‚             â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      2. MODELS                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            Arquitecturas Probadas                    â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  â€¢ DenseNet121    âœ… MEJOR MODELO (RÂ² > 0.97)       â”‚   â”‚
â”‚  â”‚  â€¢ ResNet50                                          â”‚   â”‚
â”‚  â”‚  â€¢ EfficientNetB2/B7                                 â”‚   â”‚
â”‚  â”‚  â€¢ InceptionNetV3                                    â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  Entrenamiento:                                      â”‚   â”‚
â”‚  â”‚  â”œâ”€ Train/Val Split: 90/10                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ Optimizador: Adam                               â”‚   â”‚
â”‚  â”‚  â”œâ”€ Loss: MSE                                        â”‚   â”‚
â”‚  â”‚  â”œâ”€ Transfer Learning: ImageNet weights             â”‚   â”‚
â”‚  â”‚  â””â”€ Fine-tuning de capas finales                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    3. RESULTS                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              AnÃ¡lisis de Interpretabilidad           â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  ğŸ“Š MÃ©tricas de Performance:                         â”‚   â”‚
â”‚  â”‚     â€¢ RÂ² Score                                       â”‚   â”‚
â”‚  â”‚     â€¢ MAPE (Mean Absolute Percentage Error)          â”‚   â”‚
â”‚  â”‚     â€¢ SMAPE (Symmetric MAPE)                         â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  ğŸ” VisualizaciÃ³n de Features:                       â”‚   â”‚
â”‚  â”‚     â€¢ UMAP por capa de la red                        â”‚   â”‚
â”‚  â”‚     â€¢ Clustering de activaciones                     â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  ğŸ¨ Grad-CAM (Interpretabilidad):                    â”‚   â”‚
â”‚  â”‚     â€¢ Heatmaps de atenciÃ³n del modelo               â”‚   â”‚
â”‚  â”‚     â€¢ AnÃ¡lisis por rangos de parÃ¡metros             â”‚   â”‚
â”‚  â”‚     â€¢ IdentificaciÃ³n de regiones crÃ­ticas           â”‚   â”‚
â”‚  â”‚     â€¢ AnÃ¡lisis de contribuciÃ³n por capa              â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  ğŸ“ˆ Experimentos de AblaciÃ³n:                        â”‚   â”‚
â”‚  â”‚     â€¢ Enmascaramiento de regiones                   â”‚   â”‚
â”‚  â”‚     â€¢ Impacto en performance                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
codigo/
â”œâ”€â”€ preprocessing/          # ConstrucciÃ³n y preparaciÃ³n de datos
â”‚   â”œâ”€â”€ Databasejex2T/
â”‚   â”‚   â”œâ”€â”€ Construction.ipynb          # Construye dataset desde .dat
â”‚   â”‚   â””â”€â”€ DescriptionRescale.ipynb    # AnÃ¡lisis y normalizaciÃ³n
â”‚   â””â”€â”€ DatabaseKDMT/
â”‚       â”œâ”€â”€ Construction.ipynb
â”‚       â””â”€â”€ DescriptionRescale.ipynb
â”‚
â”œâ”€â”€ Models/                 # Entrenamiento de modelos
â”‚   â”œâ”€â”€ DatabaseJex2T/
â”‚   â”‚   â”œâ”€â”€ DenseNetFinal.ipynb         # âœ… Mejor modelo
â”‚   â”‚   â”œâ”€â”€ EfficienNetFinal.ipynb
â”‚   â”‚   â””â”€â”€ ResNetFinal.ipynb
â”‚   â””â”€â”€ DatabaseKDMT/
â”‚       â”œâ”€â”€ DenseNet121KDM.ipynb
â”‚       â”œâ”€â”€ EfficientNetB2KDM.ipynb
â”‚       â”œâ”€â”€ EfficientNetKDM.ipynb
â”‚       â”œâ”€â”€ InceptionNetKDM.ipynb
â”‚       â””â”€â”€ ResNetKDM.ipynb
â”‚
â””â”€â”€ Results/                # AnÃ¡lisis e interpretabilidad
    â”œâ”€â”€ DatabaseJex2T/
    â”‚   â””â”€â”€ Results.ipynb               # AnÃ¡lisis completo Jex2/T
    â””â”€â”€ DatabaseKDMT/
        â””â”€â”€ Results.ipynb               # AnÃ¡lisis completo KDM/T
```

## ğŸ† Resultados Principales

### DatabaseJex2T (ParÃ¡metro Jex2)

**Modelo:** DenseNet121

| MÃ©trica | Valor |
|---------|-------|
| **RÂ² Score** | **0.9753** |
| MAPE | 18.64% |
| SMAPE | 15.49% |

**InterpretaciÃ³n:**
- El modelo captura exitosamente la relaciÃ³n entre patrones de spin y Jex2
- Las capas profundas (conv4, conv5) muestran mayor sensibilidad a variaciones del parÃ¡metro
- Grad-CAM revela que el modelo se enfoca en interfaces de dominios magnÃ©ticos

### DatabaseJex2T (Temperatura)

**Modelo:** DenseNet121

| MÃ©trica | Valor |
|---------|-------|
| RÂ² Score | -1.2353 |
| MAPE | 287.11% |
| SMAPE | 67.29% |

**InterpretaciÃ³n:**
- La temperatura es mÃ¡s difÃ­cil de predecir desde configuraciones estÃ¡ticas
- Sugiere que mÃºltiples temperaturas pueden producir configuraciones similares
- Requiere informaciÃ³n adicional (dinÃ¡mica temporal, fluctuaciones)

## ğŸ”¬ MetodologÃ­a

### 1. Preprocesamiento
- **Input:** Archivos .dat con coordenadas y componentes de spin
- **TransformaciÃ³n:** ConversiÃ³n a imÃ¡genes 2D de magnetizaciÃ³n (componente Sz)
- **NormalizaciÃ³n:** MinMaxScaler sobre valores de magnetizaciÃ³n
- **Resize:** 39Ã—39 â†’ 224Ã—224 (requerido por CNNs pre-entrenadas)
- **Augmentation:** RepeticiÃ³n en 3 canales RGB (compatibilidad ImageNet)

### 2. Arquitecturas de Modelos

**DenseNet121** (Seleccionado como mejor modelo):
- Conexiones densas entre capas â†’ mejor flujo de gradientes
- Transfer learning desde ImageNet
- Capa final: Global Average Pooling â†’ Dense(1) para regresiÃ³n
- ParÃ¡metros entrenables: ~7M

**Otras arquitecturas probadas:**
- ResNet50: Residual connections
- EfficientNetB2/B7: Compound scaling
- InceptionNetV3: Multi-scale feature extraction

### 3. Entrenamiento
- **Loss function:** Mean Squared Error (MSE)
- **Optimizer:** Adam (lr=1e-4)
- **Batch size:** 32
- **Train/Val split:** 90/10
- **Early stopping:** Patience=10 epochs
- **Callbacks:** ModelCheckpoint, ReduceLROnPlateau

### 4. Interpretabilidad

**UMAP (Uniform Manifold Approximation and Projection):**
- VisualizaciÃ³n de activaciones intermedias
- AnÃ¡lisis de separabilidad en espacio latente
- IdentificaciÃ³n de clusters por rango de parÃ¡metros

**Grad-CAM (Gradient-weighted Class Activation Mapping):**
- Heatmaps de atenciÃ³n del modelo
- AnÃ¡lisis por capa (conv2 â†’ conv5)
- IdentificaciÃ³n de regiones crÃ­ticas para predicciÃ³n
- ContribuciÃ³n promedio por rango de parÃ¡metros

**Experimentos de AblaciÃ³n:**
- Enmascaramiento de regiones de alta/baja atenciÃ³n
- MediciÃ³n de impacto en RÂ² score
- ValidaciÃ³n de interpretaciones Grad-CAM

## ğŸ“Š Visualizaciones Clave

### 1. UMAP de Activaciones
Muestra cÃ³mo las capas de la red separan progresivamente las muestras segÃºn su valor de parÃ¡metro.

### 2. Grad-CAM Heatmaps
Revela quÃ© regiones espaciales de la imagen son mÃ¡s importantes para la predicciÃ³n.

### 3. AnÃ¡lisis por Rangos
Divide el espacio de parÃ¡metros en 5 rangos y analiza el comportamiento del modelo en cada uno.

### 4. ContribuciÃ³n por Capa
GrÃ¡fico de barras mostrando la importancia relativa de cada capa convolucional.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.10+**
- **TensorFlow/Keras 2.x** - Deep Learning
- **NumPy, Pandas** - ManipulaciÃ³n de datos
- **Matplotlib, Seaborn** - VisualizaciÃ³n
- **UMAP-learn** - ReducciÃ³n dimensional
- **scikit-learn** - MÃ©tricas y preprocesamiento
- **OpenCV (cv2)** - Procesamiento de imÃ¡genes
- **Google Colab** - Entrenamiento con GPU

## ğŸš€ CÃ³mo Usar

### 1. Construir Base de Datos
```bash
# Ejecutar notebook de construcciÃ³n
codigo/preprocessing/Databasejex2T/Construction.ipynb
```

### 2. Entrenar Modelo
```bash
# Ejecutar notebook de modelo seleccionado
codigo/Models/DatabaseJex2T/DenseNetFinal.ipynb
```

### 3. Analizar Resultados
```bash
# Ejecutar anÃ¡lisis de interpretabilidad
codigo/Results/DatabaseJex2T/Results.ipynb
```

## ğŸ“ Notebooks Clave

| Notebook | DescripciÃ³n | Tiempo estimado |
|----------|-------------|-----------------|
| `Construction.ipynb` | Construye dataset desde simulaciones | 15-30 min |
| `DenseNetFinal.ipynb` | Entrena modelo DenseNet | 2-4 horas (GPU) |
| `Results.ipynb` | AnÃ¡lisis completo de interpretabilidad | 30-60 min |

## ğŸ” PrÃ³ximos Pasos

- [ ] Explorar arquitecturas tipo Vision Transformer (ViT)
- [ ] Incorporar informaciÃ³n temporal (series de configuraciones)
- [ ] Multi-task learning (predecir mÃºltiples parÃ¡metros simultÃ¡neamente)
- [ ] AnÃ¡lisis de incertidumbre (Bayesian Neural Networks)
- [ ] ValidaciÃ³n en datos experimentales reales

## ğŸ“š Referencias

- **DenseNet:** Huang et al. (2017) - Densely Connected Convolutional Networks
- **Grad-CAM:** Selvaraju et al. (2017) - Grad-CAM: Visual Explanations from Deep Networks
- **UMAP:** McInnes et al. (2018) - UMAP: Uniform Manifold Approximation and Projection

## ğŸ‘¤ Autor

Juan SebastiÃ¡n MÃ©ndez RondÃ³n
Proyecto de Doctorado - Dominios MagnÃ©ticos y Deep Learning

---

**Ãšltima actualizaciÃ³n:** Diciembre 2025
