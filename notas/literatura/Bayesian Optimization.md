# Bayesian Optimization

## Definici√≥n

Bayesian Optimization (BO) es una **t√©cnica de optimizaci√≥n basada en modelos probabil√≠sticos** dise√±ada para encontrar el √≥ptimo de funciones objetivo que son:

- **Costosas de evaluar** (ej: entrenar un modelo de deep learning por horas)
- **Sin gradientes disponibles** (black-box functions)
- **Con ruido en las observaciones**
- **De alta dimensionalidad limitada** (t√≠picamente < 20 dimensiones)

En lugar de probar al azar (Random Search) o exhaustivamente (Grid Search) todas las configuraciones de hiperpar√°metros, BO construye un **modelo estad√≠stico aproximado** (surrogate model) de la funci√≥n objetivo y usa este modelo para decidir inteligentemente qu√© configuraciones evaluar a continuaci√≥n.

**Ventaja clave**: Encuentra hiperpar√°metros √≥ptimos con **menos evaluaciones** ‚Üí m√°s sample-efficient.

---

## Motivaci√≥n: Problema de Optimizaci√≥n de Hiperpar√°metros

En Machine Learning, antes de entrenar un modelo, se deben fijar **hiperpar√°metros**:

- Learning rate ($\alpha$)
- N√∫mero de capas
- Batch size
- N√∫mero de √°rboles (en Random Forest)
- Regularizaci√≥n ($\lambda$)
- etc.

**Objetivo**: Encontrar la configuraci√≥n que maximice una m√©trica (accuracy, F1-score, etc.) o minimice un error (loss, RMSE, etc.).

---

## M√©todos Tradicionales vs Bayesian Optimization

### 1. Grid Search

**Funcionamiento**:
- Recorre TODAS las combinaciones posibles en una "rejilla" predefinida
- Garantiza probar todo el espacio discretizado

**Ventajas**:
- Simple de implementar
- Reproducible
- No requiere teor√≠a sofisticada

**Desventajas**:
- ‚ùå Explota en complejidad: $O(d^n)$ donde $d$ = valores por dimensi√≥n, $n$ = n√∫mero de hiperpar√°metros
- ‚ùå Muy lento: desperdicia tiempo en configuraciones malas
- ‚ùå No aprende de evaluaciones previas

**Ejemplo**:
```python
learning_rates = [0.001, 0.01, 0.1]
batch_sizes = [16, 32, 64, 128]
# Total: 3 √ó 4 = 12 evaluaciones
```

### 2. Random Search

**Funcionamiento**:
- Escoge combinaciones **al azar** del espacio de b√∫squeda
- Eval√∫a un presupuesto fijo de configuraciones

**Ventajas**:
- Suele encontrar algo decente m√°s r√°pido que Grid Search
- Mejor en espacios de alta dimensi√≥n
- F√°cil de paralelizar

**Desventajas**:
- ‚ùå A√∫n no usa informaci√≥n previa ‚Üí sigue siendo "ciego"
- ‚ùå No balancea exploraci√≥n vs explotaci√≥n
- ‚ùå Puede probar configuraciones muy similares por azar

### 3. Bayesian Optimization ‚úÖ

**Funcionamiento**:
- **Aprende de lo ya probado**
- Usa un modelo probabil√≠stico que balancea:
  - **Explotaci√≥n**: Probar cerca de los mejores hiperpar√°metros encontrados
  - **Exploraci√≥n**: Probar en zonas poco exploradas que podr√≠an ser mejores

**Ventajas**:
- ‚úÖ Sample-efficient: Menos evaluaciones para encontrar el √≥ptimo
- ‚úÖ Usa informaci√≥n acumulada inteligentemente
- ‚úÖ Cuantifica incertidumbre en predicciones
- ‚úÖ Adaptable a restricciones y costos

**Desventajas**:
- M√°s complejo de implementar
- Overhead computacional del surrogate model
- No siempre mejor que Random Search en alta dimensi√≥n (> 20D)

---

## ¬øC√≥mo Funciona Bayesian Optimization?

Bayesian Optimization tiene **3 componentes fundamentales**:

1. **Surrogate Model** (Modelo Sustituto)
2. **Acquisition Function** (Funci√≥n de Adquisici√≥n)
3. **Optimization Loop** (Bucle Iterativo)

![Figura: Diagrama de flujo de Bayesian Optimization]
<!-- TODO: Agregar diagrama de flujo BO -->

---

## 1. Surrogate Model

### Definici√≥n

Es un **modelo probabil√≠stico barato** que intenta predecir el valor de la funci√≥n objetivo real $f(x)$ sin tener que evaluarla.

**Caracter√≠sticas clave**:
- No solo predice un valor ‚Üí tambi√©n dice **cu√°nta confianza** tiene (incertidumbre)
- Se actualiza con cada nueva observaci√≥n
- Es computacionalmente eficiente comparado con entrenar el modelo real

### Tipos de Surrogate Models

#### A) Gaussian Process (GP) üîµ

**¬øQu√© es?**

Un GP es un modelo probabil√≠stico que genera una **distribuci√≥n sobre funciones suaves**. Dado un conjunto de puntos evaluados, un GP predice:
- La **media** $\mu(x)$: mejor estimaci√≥n de $f(x)$
- La **varianza** $\sigma^2(x)$: incertidumbre en la predicci√≥n

**Formulaci√≥n matem√°tica**:

$$f(x) \sim \text{GP}(\mu(x), \kappa(x, x'))$$

Donde:
- $\mu(x)$: funci√≥n de media (usualmente se asume 0)
- $\kappa(x, x')$: **funci√≥n kernel** que mide la covarianza entre puntos

**Kernels comunes**:

1. **RBF (Radial Basis Function)**:
   $$\kappa(x, x') = \sigma^2 \exp\left(-\frac{\|x - x'\|^2}{2\ell^2}\right)$$
   - Asume que puntos cercanos tienen valores similares
   - $\ell$: length-scale (controla qu√© tan r√°pido decae la correlaci√≥n)

2. **Mat√©rn**:
   $$\kappa(x, x') = \frac{2^{1-\nu}}{\Gamma(\nu)} \left(\frac{\sqrt{2\nu}\|x-x'\|}{\ell}\right)^\nu K_\nu\left(\frac{\sqrt{2\nu}\|x-x'\|}{\ell}\right)$$
   - M√°s flexible que RBF
   - $\nu$ controla la suavidad

**Intuici√≥n visual**:

> Imagina que pintas una **curva suave** sobre los puntos que ya probaste. A medida que te alejas de puntos conocidos, la "pintura se vuelve borrosa" ‚Üí **mayor incertidumbre**.

![Figura: GP con media y banda de incertidumbre]
<!-- TODO: Agregar figura de GP mostrando Œº(x) ¬± 2œÉ(x) -->

**Ventajas**:
- ‚úÖ Excelente estimaci√≥n de incertidumbre
- ‚úÖ Ideal para acquisition functions (exploraci√≥n vs explotaci√≥n)
- ‚úÖ Funciona muy bien en espacios de baja dimensi√≥n (< 20 hiperpar√°metros)
- ‚úÖ Si la funci√≥n es suave y continua, muy eficiente
- ‚úÖ Solidez matem√°tica y te√≥rica

**Desventajas**:
- ‚ùå No escala bien: $O(n^3)$ con n√∫mero de puntos evaluados
- ‚ùå Problemas en alta dimensionalidad (> 20D)
- ‚ùå Asume suavidad: puede fallar en funciones discontinuas
- ‚ùå Selecci√≥n de kernel puede afectar rendimiento

#### B) Tree-structured Parzen Estimator (TPE) üå≥

**¬øQu√© es?**

En vez de modelar directamente $f(x)$, TPE modela la **distribuci√≥n de configuraciones** que dieron:
- Resultados **buenos** ‚Üí $p(x | y < y^*)$
- Resultados **malos** ‚Üí $p(x | y \geq y^*)$

Luego busca nuevos puntos en regiones con alta densidad de configuraciones "buenas".

**Formulaci√≥n**:

$$p(x | y) =
\begin{cases}
\ell(x) & \text{si } y < y^* \text{ (buenos)}\\
g(x) & \text{si } y \geq y^* \text{ (malos)}
\end{cases}$$

Donde $y^*$ es un percentil (ej: top 15% de resultados).

**Ventajas**:
- ‚úÖ Escala mucho mejor a espacios de mayor dimensi√≥n
- ‚úÖ Funciona bien con hiperpar√°metros **categ√≥ricos** y **mixtos** (enteros, booleanos, listas)
- ‚úÖ Implementado en librer√≠as populares (Hyperopt)
- ‚úÖ Menos costoso computacionalmente que GP

**Desventajas**:
- ‚ùå Estimaci√≥n de incertidumbre menos precisa que GP
- ‚ùå Menos "te√≥rico" ‚Üí m√°s heur√≠stico
- ‚ùå No aprovecha estructura suave de la funci√≥n

#### C) Adaptive Tree-structured Parzen Estimator (ATPE) üîÑ

**¬øQu√© es?**

Una versi√≥n **mejorada de TPE** que ajusta autom√°ticamente sus hiperpar√°metros internos:
- Percentiles que definen "bueno" vs "malo"
- Par√°metros de las distribuciones $\ell(x)$ y $g(x)$

**Ventajas**:
- ‚úÖ M√°s robusto que TPE en distintos escenarios
- ‚úÖ Encuentra mejores soluciones m√°s r√°pido
- ‚úÖ Auto-tuning de par√°metros internos

**Desventajas**:
- ‚ùå M√°s complejo de entender
- ‚ùå Todav√≠a heur√≠stico (no tiene solidez matem√°tica de GP)

#### D) Otros Surrogate Models

- **Random Forest**: Ensemble de √°rboles de decisi√≥n
- **Gradient Boosted Trees**: XGBoost, LightGBM
- **Neural Networks**: Para espacios muy complejos

---

## 2. Acquisition Function

### Definici√≥n

Dada la predicci√≥n del surrogate model, la **acquisition function** $\alpha(x)$ define una **regla** para elegir el siguiente punto $x_{next}$ a evaluar con la funci√≥n objetivo real.

**Objetivo**: Balancear **explotaci√≥n** vs **exploraci√≥n**

$$x_{next} = \arg\max_{x} \alpha(x)$$

### Principales Acquisition Functions

#### A) Probability of Improvement (PI)

**Idea**: Maximizar la probabilidad de mejorar el mejor valor observado hasta ahora.

$$\text{PI}(x) = P(f(x) > f(x^+)) = \Phi\left(\frac{\mu(x) - f(x^+)}{\sigma(x)}\right)$$

Donde:
- $f(x^+)$ = mejor valor observado
- $\Phi$ = funci√≥n CDF de la normal est√°ndar

**Caracter√≠stica**: Muy conservadora (tiende a explotar)

#### B) Expected Improvement (EI) ‚≠ê [M√ÅS USADA]

**Idea**: Maximizar la **mejora esperada** sobre el mejor valor.

$$\text{EI}(x) = \mathbb{E}[\max(f(x) - f(x^+), 0)] =
\begin{cases}
(\mu(x) - f(x^+))\Phi(Z) + \sigma(x)\phi(Z) & \text{si } \sigma(x) > 0\\
0 & \text{si } \sigma(x) = 0
\end{cases}$$

Donde $Z = \frac{\mu(x) - f(x^+)}{\sigma(x)}$

**Ventaja**: Buen balance entre exploraci√≥n y explotaci√≥n

#### C) Upper Confidence Bound (UCB)

**Idea**: Optimismo ante la incertidumbre.

$$\text{UCB}(x) = \mu(x) + \kappa \cdot \sigma(x)$$

Donde $\kappa$ controla el balance exploraci√≥n/explotaci√≥n:
- $\kappa$ alto ‚Üí m√°s exploraci√≥n
- $\kappa$ bajo ‚Üí m√°s explotaci√≥n

**Caracter√≠stica**: Simple y efectiva

#### D) Thompson Sampling

**Idea**: Muestrear funciones del posterior del GP y optimizar la muestra.

**Ventaja**: Naturalmente estoc√°stico ‚Üí bueno para paralelizaci√≥n

---

## 3. Bucle Iterativo (Sequential Model-Based Optimization - SMBO)

### Algoritmo General

```
1. Definir espacio de b√∫squeda S
2. Inicializar con n_init evaluaciones aleatorias
3. FOR iteraci√≥n t = n_init+1 to n_max:
   a) Entrenar surrogate model con datos observados
   b) Optimizar acquisition function para encontrar x_next
   c) Evaluar f(x_next) con funci√≥n objetivo real
   d) A√±adir (x_next, f(x_next)) al conjunto de datos
4. RETURN mejor configuraci√≥n encontrada
```

### Flujo Detallado

#### Paso 1: Definir Search Space

El usuario define:
- Rangos para hiperpar√°metros continuos: $x_i \in [a, b]$
- Opciones para categ√≥ricos: $x_j \in \{\text{Adam}, \text{SGD}, \text{RMSprop}\}$
- Distribuciones: uniforme, log-uniforme, normal, etc.

**Ejemplo**:
```python
space = {
    'learning_rate': hp.loguniform('lr', np.log(1e-5), np.log(1e-1)),
    'batch_size': hp.choice('bs', [16, 32, 64, 128]),
    'n_layers': hp.quniform('layers', 2, 10, 1),
    'activation': hp.choice('act', ['relu', 'tanh', 'elu'])
}
```

#### Paso 2: Random Sampling Inicial

Se toman $n_{init}$ (t√≠picamente 5-10) configuraciones **aleatorias** para:
- Construir un historial inicial $\mathcal{H} = \{(x_1, y_1), \ldots, (x_{n_{init}}, y_{n_{init}})\}$
- Dar informaci√≥n diversa al surrogate model

**¬øPor qu√© aleatorio?**
- Sin evaluaciones previas, no hay informaci√≥n para guiar la b√∫squeda
- Evita sesgo inicial

#### Paso 3: Construcci√≥n del Modelo Probabil√≠stico

Con el historial $\mathcal{H}$, se entrena el surrogate model:

$$p(y \mid x, \mathcal{H}) \approx p_{\text{surrogate}}(y \mid x)$$

**Para GP**:
- Se ajustan hiperpar√°metros del kernel (length-scale, variance)
- Se calcula la distribuci√≥n posterior: $p(f \mid \mathcal{H})$

**Para TPE**:
- Se dividen observaciones en "buenas" ($y < y^*$) y "malas" ($y \geq y^*$)
- Se estiman $\ell(x)$ y $g(x)$ usando kernel density estimation

#### Paso 4: Optimizaci√≥n de Acquisition Function

Se resuelve:

$$x_{next} = \arg\max_{x \in S} \alpha(x \mid \mathcal{H})$$

**M√©todos de optimizaci√≥n**:
- Para espacios continuos: L-BFGS, DIRECT, CMA-ES
- Para espacios mixtos: Grid search sobre acquisition, evolutionary algorithms

#### Paso 5: Evaluaci√≥n Real

- Se entrena el modelo con configuraci√≥n $x_{next}$
- Se mide la m√©trica objetivo: $y_{next} = f(x_{next})$
- **Esta es la parte costosa** (puede tomar horas)

#### Paso 6: Actualizaci√≥n del Historial

$$\mathcal{H} \leftarrow \mathcal{H} \cup \{(x_{next}, y_{next})\}$$

El surrogate model se vuelve **m√°s preciso** con cada iteraci√≥n.

![Figura: Evoluci√≥n del GP a trav√©s de iteraciones]
<!-- TODO: Agregar animaci√≥n o secuencia de GPs actualiz√°ndose -->

---

## Preguntas Frecuentes

### ¬øCu√°ntas muestras iniciales necesito?

**Recomendaci√≥n general**:
- Espacios simples (< 5 dim): $n_{init} = 5$
- Espacios medianos (5-10 dim): $n_{init} = 10-20$
- Espacios complejos (> 10 dim): $n_{init} = 50-100$

**Regla emp√≠rica**: $n_{init} \approx 2 \times d$ donde $d$ = dimensionalidad

### ¬øC√≥mo establecer los l√≠mites del search space?

**Estrategias**:

1. **Experiencia previa**: Usar valores t√≠picos de la literatura
2. **√ìrdenes de magnitud**: Para learning rate: $[10^{-5}, 10^{-1}]$
3. **Escalas logar√≠tmicas**: Para par√°metros que var√≠an exponencialmente
4. **Restricciones f√≠sicas**: Batch size debe ser potencia de 2 para eficiencia

**Cuidado**:
- Si el l√≠mite es muy estrecho ‚Üí puede excluir el √≥ptimo
- Si es muy amplio ‚Üí necesitas m√°s evaluaciones

### ¬øCu√°ndo detener la optimizaci√≥n?

**Criterios de parada**:

1. **Presupuesto fijo**: $n_{max}$ evaluaciones
2. **Convergencia**: No hay mejora en $k$ iteraciones consecutivas
3. **Tiempo l√≠mite**: Wall-clock time
4. **Objetivo alcanzado**: $f(x) >$ umbral deseado

---

## Comparaci√≥n de Surrogate Models

| Caracter√≠stica | Gaussian Process | TPE | ATPE | Random Forest |
|---------------|------------------|-----|------|---------------|
| **Incertidumbre** | Excelente | Buena | Buena | Moderada |
| **Dimensionalidad** | Baja (< 20) | Media-Alta | Media-Alta | Media |
| **Categ√≥ricos** | Dif√≠cil | Excelente | Excelente | Bueno |
| **Complejidad** | $O(n^3)$ | $O(n \log n)$ | $O(n \log n)$ | $O(nt \log n)$ |
| **Interpretabilidad** | Alta (te√≥rico) | Media (heur√≠stico) | Baja | Media |
| **Sample Efficiency** | Muy Alta | Alta | Muy Alta | Media |

**Recomendaci√≥n por caso**:

- **Funciones suaves, < 10 dim, budget peque√±o**: Gaussian Process con EI
- **Espacios mixtos, > 10 dim, categ√≥ricos**: TPE o ATPE
- **Alta dimensionalidad (> 20 dim), muchos evaluaciones**: Random Forest + UCB
- **Paralelizaci√≥n masiva**: Thompson Sampling

---

## Herramientas en Python

### 1. Optuna ‚≠ê [RECOMENDADO]

**URL**: https://optuna.org/

**Caracter√≠sticas**:
- Interfaz moderna y limpia
- TPE como default (escalable)
- Pruning autom√°tico de trials malos
- Visualizaciones interactivas
- Paralelizaci√≥n nativa
- Integraci√≥n con frameworks (PyTorch, TensorFlow, Keras)

**Ejemplo**:
```python
import optuna

def objective(trial):
    x = trial.suggest_float('x', -10, 10)
    return (x - 2) ** 2

study = optuna.create_study()
study.optimize(objective, n_trials=100)

print(f"Best value: {study.best_value}")
print(f"Best params: {study.best_params}")
```

### 2. Hyperopt

**URL**: https://hyperopt.github.io/hyperopt/

**Caracter√≠sticas**:
- Implementaci√≥n original de TPE
- Muy usado en Kaggle
- Espacios de b√∫squeda flexibles
- MongoDB para paralelizaci√≥n

**Ejemplo**:
```python
from hyperopt import hp, fmin, tpe, Trials

space = {
    'x': hp.uniform('x', -10, 10),
    'y': hp.choice('y', [1, 2, 3])
}

best = fmin(
    fn=lambda params: (params['x'] - 2)**2,
    space=space,
    algo=tpe.suggest,
    max_evals=100
)
```

### 3. scikit-optimize

**URL**: https://scikit-optimize.github.io/stable/

**Caracter√≠sticas**:
- Gaussian Process como default
- API estilo scikit-learn
- Varias acquisition functions (EI, PI, LCB)
- Diagn√≥stico y visualizaci√≥n

**Ejemplo**:
```python
from skopt import gp_minimize

def objective(params):
    x, y = params
    return x**2 + y**2

result = gp_minimize(
    objective,
    [(-5.0, 5.0), (-5.0, 5.0)],
    n_calls=50,
    random_state=42
)
```

### 4. Ray Tune

**URL**: https://docs.ray.io/en/latest/tune/index.html

**Caracter√≠sticas**:
- Escalabilidad a clusters
- Early stopping autom√°tico
- Integraci√≥n con Ray (paralelizaci√≥n distribuida)
- Soporte para m√∫ltiples algoritmos (Optuna, HyperOpt, Ax)

---

## Ejemplo Completo: Optimizar Hiperpar√°metros de Red Neuronal

```python
import optuna
from tensorflow import keras
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split

# Cargar datos
X, y = load_digits(return_X_y=True)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)

def objective(trial):
    # Hiperpar√°metros a optimizar
    n_layers = trial.suggest_int('n_layers', 1, 3)
    n_units = trial.suggest_int('n_units', 32, 256)
    dropout = trial.suggest_float('dropout', 0.1, 0.5)
    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)

    # Construir modelo
    model = keras.Sequential()
    model.add(keras.layers.Input(shape=(64,)))

    for i in range(n_layers):
        model.add(keras.layers.Dense(n_units, activation='relu'))
        model.add(keras.layers.Dropout(dropout))

    model.add(keras.layers.Dense(10, activation='softmax'))

    # Compilar
    model.compile(
        optimizer=keras.optimizers.Adam(lr),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    # Entrenar
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=10,
        batch_size=32,
        verbose=0
    )

    # Retornar m√©trica a MAXIMIZAR (Optuna minimiza por default)
    return history.history['val_accuracy'][-1]

# Crear estudio (maximizaci√≥n)
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

# Resultados
print(f"Mejor accuracy: {study.best_value:.4f}")
print(f"Mejores hiperpar√°metros: {study.best_params}")
```

---

## Ventajas y Limitaciones

### Ventajas ‚úÖ

1. **Sample efficiency**: Encuentra buenos hiperpar√°metros con ~20-100 evaluaciones (vs miles en Grid/Random)
2. **Adaptativo**: Aprende de evaluaciones previas
3. **Cuantifica incertidumbre**: Sabe d√≥nde tiene confianza y d√≥nde no
4. **Flexible**: Espacios mixtos (continuos, discretos, categ√≥ricos)
5. **Te√≥ricamente fundamentado**: Garant√≠as de convergencia (bajo ciertas condiciones)

### Limitaciones ‚ùå

1. **Alta dimensionalidad**: Sufre en > 20-50 dimensiones (curse of dimensionality)
2. **Overhead computacional**: El surrogate puede ser costoso de entrenar
3. **Asunciones de suavidad**: GP asume funciones suaves (puede fallar en discontinuas)
4. **Paralelizaci√≥n dif√≠cil**: El algoritmo es inherentemente secuencial
5. **Elecci√≥n de kernel/surrogate**: Puede afectar el rendimiento significativamente

---

## Extensiones y Variantes

### Multi-Objective Bayesian Optimization

Optimizar m√∫ltiples objetivos simult√°neamente:
- Maximizar accuracy
- Minimizar tiempo de entrenamiento
- Minimizar uso de memoria

**Algoritmos**: NSGA-II con GP, ParEGO

### Multi-Fidelity Bayesian Optimization

Usar evaluaciones de baja fidelidad (menos epochs, menos datos) para guiar la b√∫squeda:

- **Hyperband**: Asigna recursos adaptativamente
- **BOHB**: Combina Hyperband con BO

### Contextual Bayesian Optimization

Optimizar considerando contexto (ej: diferentes datasets):

$$\max_{x} f(x, c) \quad \text{donde } c \text{ es el contexto}$$

---

## Referencias Clave

1. **Snoek, J., Larochelle, H., & Adams, R. P. (2012).** "Practical Bayesian Optimization of Machine Learning Algorithms." *NeurIPS 2012*. [Paper cl√°sico que populariz√≥ BO en ML]

2. **Bergstra, J., Bardenet, R., Bengio, Y., & K√©gl, B. (2011).** "Algorithms for Hyper-Parameter Optimization." *NeurIPS 2011*. [Introduce TPE]

3. **Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., & De Freitas, N. (2016).** "Taking the Human Out of the Loop: A Review of Bayesian Optimization." *Proceedings of the IEEE*. [Review comprehensivo]

4. **Frazier, P. I. (2018).** "A Tutorial on Bayesian Optimization." *arXiv:1807.02811*. [Tutorial te√≥rico detallado]

---

## Conclusi√≥n

Bayesian Optimization es una herramienta poderosa para:
- Optimizaci√≥n de hiperpar√°metros
- AutoML
- Dise√±o de experimentos
- Optimizaci√≥n de procesos industriales

**Cu√°ndo usar BO**:
- ‚úÖ Funci√≥n objetivo costosa de evaluar (> 1 minuto por evaluaci√≥n)
- ‚úÖ Dimensionalidad baja-media (< 20 hiperpar√°metros)
- ‚úÖ Budget limitado (< 500 evaluaciones)
- ‚úÖ Necesitas interpretabilidad (incertidumbre)

**Cu√°ndo NO usar BO**:
- ‚ùå Funci√≥n barata (< 1 segundo) ‚Üí usa Grid/Random
- ‚ùå Alta dimensionalidad (> 50) ‚Üí usa Hyperband o evolutionary algorithms
- ‚ùå Budget masivo (> 10,000 evaluaciones) ‚Üí Random Search puede ser suficiente

---

## Tareas Pendientes

- [ ] Crear figura: Diagrama de flujo de Bayesian Optimization
- [ ] Crear figura: GP con media y banda de incertidumbre
- [ ] Crear figura: Evoluci√≥n del GP a trav√©s de iteraciones
- [ ] Crear figura: Comparaci√≥n visual Grid vs Random vs Bayesian
- [ ] Crear figura: Acquisition functions (EI, PI, UCB)
- [ ] Agregar notebook de ejemplo con Optuna
- [ ] Agregar comparaci√≥n emp√≠rica de tiempos de ejecuci√≥n

---

**√öltima actualizaci√≥n**: Diciembre 2025
