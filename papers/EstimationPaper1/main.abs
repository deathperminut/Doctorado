The investigation of magnetic domain structures in nanoscale materials is essential for advancing emerging technologies in spintronics, biomedicine, and energy storage. \textcolor{blue}{These magnetic textures arise from high-resolution imaging techniques or from simulations that model atomistic spin interactions at the nanoscale}. However, the quantitative interpretation of these domains from experimental images remains challenging due to the complexity of inferring the physical parameters associated. This disconnect between experimental visualization and physical models hinders both theoretical validation and the prediction of magnetic behavior in new functional materials. Deep learning models can significantly contribute to the analysis of complex systems, enabling the extraction of patterns, the prediction of properties, and the establishment of relationships between experimental data and hidden variables that would be difficult to identify using traditional approaches. However, their application in physical parameter estimation tasks faces major challenges, such as the existence of multiple possible solutions that can lead to similar visual patterns, making it difficult to identify a unique set of parameters compatible with a given observation, \textcolor{blue}{the intrinsic variability and noise present in both simulated and experimental datasets further complicate the parameter estimation task. Small perturbations in temperature, anisotropy, or exchange interactions can lead to visually similar spin textures, increasing the risk of degeneracy and instability in regression-based predictions. To mitigate this issue, several studies have reformulated the problem as a classification task, focusing on identifying representative magnetic states or regimes rather than inferring exact numerical values. This strategy reduces sensitivity to noise, improves robustness against non-unique solutions, and provides a more tractable pathway for analyzing highly complex or disordered configurations where direct parameter estimation becomes unreliable} , as well as the limited interpretability of deep neural networks, which prevents us from knowing with certainty whether predictions are based on real physical principles or on weakly generalizable statistical correlations.\textcolor{blue}{ In this work, we propose a method based on convolutional networks to estimate physical parameters from magnetic domains, allowing not only prediction but also interpretation of the network’s latent space, thus facilitating a better understanding of the underlying physical relationships. As an additional contribution, we introduce a novel interpretability measure for layer-wise activation maps, defined as
$S(y_{\text{true}}, y_{\text{pred}}) = 1 - |y_{\text{true}} - y_{\text{pred}}|$,
which highlights the most relevant pixels in the input image by linking prediction accuracy with spatial features. This similarity-based approach provides a physics-informed way to connect model errors with localized image regions, improving transparency and reliability in the analysis of magnetic domain data.} \textcolor{blue}{
     Our results show that DenseNet121 consistently provides the most accurate and generalizable predictions for Hamiltonian parameters, particularly the Dzyaloshinskii–Moriya interaction, while the proposed Regression Activation Maps (RAMs) offer a physics-informed interpretability framework that links prediction reliability with localized magnetic structures. This demonstrates that deep learning models, when combined with tailored explainability strategies, can bridge the gap between experimental magnetic domain images and underlying physical parameters, contributing to more transparent and reliable analyses of complex nanoscale systems.
}
